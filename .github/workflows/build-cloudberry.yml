# --------------------------------------------------------------------
#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements. See the NOTICE file distributed
# with this work for additional information regarding copyright
# ownership. The ASF licenses this file to You under the Apache
# License, Version 2.0 (the "License"); you may not use this file
# except in compliance with the License. You may obtain a copy of the
# License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied. See the License for the specific language governing
# permissions and limitations under the License.
#
# --------------------------------------------------------------------
# GitHub Actions Workflow: Apache Cloudberry Build Pipeline
# --------------------------------------------------------------------
# Description:
#
#   This workflow builds, tests, and packages Apache Cloudberry on
#   Rocky Linux 9. It ensures artifact integrity, performs installation
#   tests, validates key operations, and provides detailed test reports,
#   including handling for ignored test cases.
#
# Workflow Overview:
# 1. **Check Skip**:
#    - Dynamically determines if the workflow should run based on CI skip flags.
#    - Evaluates the following fields for skip flags:
#      - **Pull Request Events**: PR title and PR body.
#      - **Push Events**: Commit message of the head commit.
#    - Supports the following skip patterns (case-insensitive):
#      - `[skip ci]`
#      - `[ci skip]`
#      - `[no ci]`
#    - **Example Usage**:
#      - Add `[skip ci]` to a commit message, PR title, or body to skip the workflow.
#
# 2. **Build Job**:
#    - Configures and builds Apache Cloudberry.
#    - Runs unit tests and verifies build artifacts.
#    - Creates RPM packages, source tarballs, and logs.
#    - **Key Artifacts**: RPM package, source tarball, build logs.
#
# 3. **RPM Install Test Job**:
#    - Verifies RPM integrity and installs Cloudberry.
#    - Validates successful installation.
#    - **Key Artifacts**: Installation logs, verification results.
#
# 4. **Test Job (Matrix)**:
#    - Executes a test matrix to validate different scenarios.
#    - Creates a demo cluster and runs installcheck tests.
#    - Parses and reports test results, including failed and ignored tests.
#    - **Key Features**:
#      - Regression diffs are displayed if found, aiding quick debugging.
#      - Both failed and ignored test names are logged and reported.
#    - **Key Artifacts**: Test logs, regression files, test summaries.
#
# 5. **Report Job**:
#    - Aggregates job results into a final report.
#    - Sends failure notifications if any step fails.
#
# Execution Environment:
# - **Runs On**: Ubuntu-latest with Rocky Linux 9 containers.
# - **Resource Requirements**:
#   - Disk: Minimum 20GB free space.
#   - Memory: Minimum 8GB RAM.
#   - CPU: Recommended 4+ cores.
#
# Triggers:
# - Push to `build-devel` branch.
# - Pull requests to `build-devel` branch.
# - Manual workflow dispatch.
#
# Container Images:
# - **Build**: `apache/incubator-cloudberry:cbdb-build-rocky9-latest`
# - **Test**: `apache/incubator-cloudberry:cbdb-test-rocky9-latest`
#
# Artifacts:
# - RPM Package          (retention: ${{ env.LOG_RETENTION_DAYS }} days).
# - Source Tarball       (retention: ${{ env.LOG_RETENTION_DAYS }} days).
# - Logs and Test Results (retention: ${{ env.LOG_RETENTION_DAYS }} days).
# - Regression Diffs      (retention: ${{ env.LOG_RETENTION_DAYS }} days).
#
# Notes:
# - Supports concurrent job execution.
# - Includes robust skip logic for pull requests and pushes.
# - Handles ignored test cases, ensuring results are comprehensive.
# - Provides detailed logs and error handling for failed and ignored tests.
# --------------------------------------------------------------------

name: Apache Cloudberry Build

on:
  workflow_dispatch:

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: false

# Note: Step details, logs, and artifacts require users to be logged into GitHub
# even for public repositories. This is a GitHub security feature and cannot
# be overridden by permissions.

permissions:
  # READ permissions allow viewing repository contents
  contents: read      # Required for checking out code and reading repository files

  # READ permissions for packages (Container registry, etc)
  packages: read      # Allows reading from GitHub package registry

  # WRITE permissions for actions includes read access to:
  # - Workflow runs
  # - Artifacts (requires GitHub login)
  # - Logs (requires GitHub login)
  actions: write

  # READ permissions for checks API:
  # - Step details visibility (requires GitHub login)
  # - Check run status and details
  checks: read

  # READ permissions for pull request metadata:
  # - PR status
  # - Associated checks
  # - Review states
  pull-requests: read

env:
  LOG_RETENTION_DAYS: 7

jobs:

  ## ======================================================================
  ## Job: record-workflow-start
  ## ======================================================================

  record-workflow-start:

    # Job Description:
    # This job logs the start of a workflow run by recording key
    # metadata (e.g., run ID, branch name, trigger type) in a
    # PostgreSQL database. The job also captures a unique workflow ID
    # from the database, which is passed to downstream jobs for
    # tracking purposes. This ensures robust monitoring and
    # traceability of workflows.

    runs-on: ubuntu-latest
    container:
      image: postgres:15
    outputs:
      workflow_id: ${{ steps.record-start.outputs.workflow_id }}
    steps:
      - name: Record workflow start
        id: record-start
        shell: bash {0}
        env:
          # Database connection details stored as secrets for security
          PGHOST: ${{ secrets.DB_HOST }}
          PGPORT: ${{ secrets.DB_PORT }}
          PGDATABASE: cloudberry_metrics
          PGUSER: github_actions
          PGPASSWORD: ${{ secrets.DB_GITHUB_ACTIONS_PASSWORD }}
        run: |
          # Determine the type of trigger that initiated the workflow
          if [[ "${{ github.event_name }}" == "pull_request" ]]; then
            TRIGGER="pull_request"
          elif [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
            TRIGGER="manual"
          else
            TRIGGER="push"
          fi
          echo "INFO: Trigger type detected as $TRIGGER"

          # Insert workflow record into the database and retrieve the generated workflow ID
          WORKFLOW_ID=$(psql sslmode=require -v ON_ERROR_STOP=1 -qtAX <<EOF
          INSERT INTO workflow_runs
            (github_run_id, github_run_attempt, trigger_type, branch_name, commit_sha, pr_number, workflow_status, started_at)
          VALUES
            (${{ github.run_id }},                     -- Unique ID for this GitHub Actions workflow run
             ${{ github.run_attempt }},                -- Number of attempts for this workflow run
             '$TRIGGER',                               -- Trigger type (e.g., push, pull_request)
             '${{ github.ref_name }}',                 -- Branch name or tag associated with the run
             '${{ github.sha }}',                      -- Commit SHA for the workflow run
             ${{ github.event.pull_request.number || 'NULL' }},  -- PR number or NULL if not applicable
             'in_progress',                            -- Initial workflow status
             NOW())                                    -- Timestamp when the workflow started
          RETURNING workflow_run_id;                   -- Retrieve the primary key of the inserted row
          EOF
          )

          # Validate the retrieved workflow ID
          if [[ -z "$WORKFLOW_ID" ]]; then
            echo "ERROR: Failed to retrieve workflow_id from database."
            exit 1
          else
            echo "INFO: Successfully retrieved workflow_id: $WORKFLOW_ID"
          fi

          # Export workflow_id for use in downstream jobs
          echo "workflow_id=${WORKFLOW_ID}" >> "$GITHUB_OUTPUT"

  ## ======================================================================
  ## Job: check-skip
  ## ======================================================================

  check-skip:
    needs: record-workflow-start
    runs-on: ubuntu-latest
    outputs:
      should_skip: ${{ steps.skip-check.outputs.should_skip }}
    steps:
      - id: skip-check
        shell: bash
        env:
          EVENT_NAME: ${{ github.event_name }}
          PR_TITLE: ${{ github.event.pull_request.title || '' }}
          PR_BODY: ${{ github.event.pull_request.body || '' }}
        run: |
          # Default to not skipping
          echo "should_skip=false" >> "$GITHUB_OUTPUT"

          # Apply skip logic only for pull_request events
          if [[ "$EVENT_NAME" == "pull_request" ]]; then
            # Combine PR title and body for skip check
            MESSAGE="${PR_TITLE}\n${PR_BODY}"

            # Escape special characters using printf %s
            ESCAPED_MESSAGE=$(printf "%s" "$MESSAGE")

            echo "Checking PR title and body (escaped): $ESCAPED_MESSAGE"

            # Check for skip patterns
            if echo -e "$ESCAPED_MESSAGE" | grep -qEi '\[skip[ -]ci\]|\[ci[ -]skip\]|\[no[ -]ci\]'; then
              echo "should_skip=true" >> "$GITHUB_OUTPUT"
            fi
          else
            echo "Skip logic is not applied for $EVENT_NAME events."
          fi

      - name: Report Skip Status
        if: steps.skip-check.outputs.should_skip == 'true'
        run: |
          echo "CI Skip flag detected in PR - skipping all checks."
          exit 0

  ## ======================================================================
  ## Job: build
  ## ======================================================================

  build:
    name: Build Apache Cloudberry
    env:
      JOB_TYPE: build
    needs:
      - record-workflow-start
      - check-skip
    runs-on: ubuntu-latest
    timeout-minutes: 120
    outputs:
      os_name: ${{ steps.capture-build-info.outputs.os_name }}
      os_version: ${{ steps.capture-build-info.outputs.os_version }}
      kernel_version: ${{ steps.capture-build-info.outputs.kernel_version }}
      cpu_count: ${{ steps.capture-build-info.outputs.cpu_count }}
      cpu_model: ${{ steps.capture-build-info.outputs.cpu_model }}
      total_memory_mb: ${{ steps.capture-build-info.outputs.total_memory_mb }}
      shared_memory: ${{ steps.capture-build-info.outputs.shared_memory }}
      disk_total: ${{ steps.capture-build-info.outputs.disk_total }}
      disk_used: ${{ steps.capture-build-info.outputs.disk_used }}
      disk_available: ${{ steps.capture-build-info.outputs.disk_available }}
      container_id: ${{ steps.capture-build-info.outputs.container_id }}
      container_image: ${{ steps.capture-build-info.outputs.container_image }}
      network_info: ${{ steps.capture-build-info.outputs.network_info }}
      process_count: ${{ steps.capture-build-info.outputs.process_count }}
      build_timestamp: ${{ steps.set_timestamp.outputs.timestamp }}

      pg_config_configure: ${{ steps.build-config.outputs.pg_config_configure }}
      postgres_version: ${{ steps.build-config.outputs.postgres_version }}
      cloudberry_version: ${{ steps.build-config.outputs.cloudberry_version }}

    container:
      image: apache/incubator-cloudberry:cbdb-build-rocky9-latest
      options: >-
        --user root
        -h cdw

    steps:
      - name: Skip Check
        if: needs.check-skip.outputs.should_skip == 'true'
        run: |
          echo "Build skipped via CI skip flag" >> "$GITHUB_STEP_SUMMARY"
          exit 0

      - name: Capture Build OS and System Information
        if: needs.check-skip.outputs.should_skip != 'true'
        id: capture-build-info
        env:
          CONTAINER_IMAGE: apache/incubator-cloudberry:cbdb-build-rocky9-latest
        shell: bash {0}
        run: |
          set -e  # Exit on error

          df -kh /
          rm -rf /__t/*
          df -kh /

          # OS Information
          OS_NAME=$(grep ^NAME= /etc/os-release | cut -d'=' -f2 | tr -d '"')
          OS_VERSION=$(grep ^VERSION_ID= /etc/os-release | cut -d'=' -f2 | tr -d '"')
          KERNEL_VERSION=$(uname -r)

          # CPU Information
          CPU_COUNT=$(nproc)
          CPU_MODEL=$(lscpu | grep "Model name" | awk -F: '{print $2}' | xargs)

          # Memory Information
          TOTAL_MEMORY=$(grep MemTotal /proc/meminfo | awk '{print $2}')
          TOTAL_MEMORY_MB=$((TOTAL_MEMORY / 1024))
          SHARED_MEMORY=$(df -h /dev/shm | awk 'NR==2 {print $2}')

          # Disk Space on '/'
          DISK_TOTAL=$(df -h / | awk 'NR==2 {print $2}')
          DISK_USED=$(df -h / | awk 'NR==2 {print $3}')
          DISK_AVAILABLE=$(df -h / | awk 'NR==2 {print $4}')

          # Container-Specific Information
          CONTAINER_ID=$(hostname)

          # Sanitize Network Information
          NETWORK_INFO=$(ip -brief addr | awk '{print $1 "=" $3}' | sed 's/@/_/g')
          PROCESS_COUNT=$(ps -e | wc -l)

          # Write outputs to $GITHUB_OUTPUT
          {
            echo "os_name=${OS_NAME}"
            echo "os_version=${OS_VERSION}"
            echo "kernel_version=${KERNEL_VERSION}"
            echo "cpu_count=${CPU_COUNT}"
            echo "cpu_model=${CPU_MODEL}"
            echo "total_memory_mb=${TOTAL_MEMORY_MB}"
            echo "shared_memory=${SHARED_MEMORY}"
            echo "disk_total=${DISK_TOTAL}"
            echo "disk_used=${DISK_USED}"
            echo "disk_available=${DISK_AVAILABLE}"
            echo "container_id=${CONTAINER_ID}"
            echo "container_image=${CONTAINER_IMAGE}"
            echo "network_info=${NETWORK_INFO}"
            echo "process_count=${PROCESS_COUNT}"
          } >> "$GITHUB_OUTPUT"

      - name: Set build timestamp
        if: needs.check-skip.outputs.should_skip != 'true'
        id: set_timestamp  # Add an ID to reference this step
        run: |
          timestamp=$(date +'%Y%m%d_%H%M%S')
          echo "timestamp=$timestamp" | tee -a "$GITHUB_OUTPUT"  # Use GITHUB_OUTPUT for job outputs
          echo "BUILD_TIMESTAMP=$timestamp" | tee -a "$GITHUB_ENV" # Also set as environment variable

      - name: Checkout Apache Cloudberry (edespino/cloudberry)
        if: needs.check-skip.outputs.should_skip != 'true'
        uses: actions/checkout@v4
        with:
          repository: edespino/cloudberry
          ref: ic-dev
          fetch-depth: 1

      - name: Checkout CI Build/Test Scripts (edespino/cloudberry-devops-release)
        if: needs.check-skip.outputs.should_skip != 'true'
        uses: actions/checkout@v4
        with:
          repository: edespino/cloudberry-devops-release
          ref: ic-dev
          path: cloudberry-devops-release

      - name: Move cloudberry-devops-release directory
        if: needs.check-skip.outputs.should_skip != 'true'
        run: |
          set -eo pipefail
          if ! mv "${GITHUB_WORKSPACE}"/cloudberry-devops-release "${GITHUB_WORKSPACE}"/..; then
            echo "::error::Container initialization failed"
            exit 1
          fi

      - name: Cloudberry Environment Initialization
        if: needs.check-skip.outputs.should_skip != 'true'
        env:
          LOGS_DIR: build-logs
        run: |
          set -eo pipefail
          if ! su - gpadmin -c "/tmp/init_system.sh"; then
            echo "::error::Container initialization failed"
            exit 1
          fi

          mkdir -p "${LOGS_DIR}/details"
          chown -R gpadmin:gpadmin .
          chmod -R 755 .
          chmod 777 "${LOGS_DIR}"

          df -h | tee -a "${LOGS_DIR}/details/disk-usage.log"
          free -h | tee -a "${LOGS_DIR}/details/memory-usage.log"

          {
            echo "=== Environment Information ==="
            uname -a
            df -h
            free -h
            env
          } | tee -a "${LOGS_DIR}/details/environment.log"

          echo "SRC_DIR=${GITHUB_WORKSPACE}" | tee -a "$GITHUB_ENV"

      - name: Generate Build Job Summary Start
        if: needs.check-skip.outputs.should_skip != 'true'
        run: |
          {
            echo "# Build Job Summary"
            echo "## Environment"
            echo "- Start Time: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
            echo "- OS Version: $(cat /etc/redhat-release)"
            echo "- GCC Version: $(gcc --version | head -n1)"
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Run Apache Cloudberry configure script
        if: needs.check-skip.outputs.should_skip != 'true'
        env:
          SRC_DIR: ${{ github.workspace }}
        run: |
          set -eo pipefail
          chmod +x "${SRC_DIR}"/../cloudberry-devops-release/build_automation/cloudberry/scripts/configure-cloudberry.sh
          if ! time su - gpadmin -c "cd ${SRC_DIR} && SRC_DIR=${SRC_DIR} ${SRC_DIR}/../cloudberry-devops-release/build_automation/cloudberry/scripts/configure-cloudberry.sh"; then
            echo "::error::Configure script failed"
            exit 1
          fi

      - name: Run Apache Cloudberry build script
        if: needs.check-skip.outputs.should_skip != 'true'
        env:
          SRC_DIR: ${{ github.workspace }}
        run: |
          set -eo pipefail
          chmod +x "${SRC_DIR}"/../cloudberry-devops-release/build_automation/cloudberry/scripts/build-cloudberry.sh
          if ! time su - gpadmin -c "cd ${SRC_DIR} && SRC_DIR=${SRC_DIR} ${SRC_DIR}/../cloudberry-devops-release/build_automation/cloudberry/scripts/build-cloudberry.sh"; then
            echo "::error::Build script failed"
            exit 1
          fi

      - name: Verify build artifacts
        if: needs.check-skip.outputs.should_skip != 'true'
        run: |
          set -eo pipefail

          echo "Verifying build artifacts..."
          {
            echo "=== Build Artifacts Verification ==="
            echo "Timestamp: $(date -u)"

            if [ ! -d "/usr/local/cloudberry-db" ]; then
              echo "::error::Build artifacts directory not found"
              exit 1
            fi

            # Verify critical binaries
            critical_binaries=(
              "/usr/local/cloudberry-db/bin/postgres"
              "/usr/local/cloudberry-db/bin/psql"
            )

            echo "Checking critical binaries..."
            for binary in "${critical_binaries[@]}"; do
              if [ ! -f "$binary" ]; then
                echo "::error::Critical binary missing: $binary"
                exit 1
              fi
              if [ ! -x "$binary" ]; then
                echo "::error::Binary not executable: $binary"
                exit 1
              fi
              echo "Binary verified: $binary"
              ls -l "$binary"
            done

            # Test binary execution
            echo "Testing binary execution..."
            if ! /usr/local/cloudberry-db/bin/postgres --version; then
              echo "::error::postgres binary verification failed"
              exit 1
            fi
            if ! /usr/local/cloudberry-db/bin/psql --version; then
              echo "::error::psql binary verification failed"
              exit 1
            fi

            echo "All build artifacts verified successfully"
          } 2>&1 | tee -a build-logs/details/build-verification.log

      - name: Create Source tarball, create RPM and verify artifacts
        if: needs.check-skip.outputs.should_skip != 'true'
        env:
          CBDB_VERSION: 99.0.0
          BUILD_NUMBER: 1
          SRC_DIR: ${{ github.workspace }}
        run: |
          set -eo pipefail

          {
            echo "=== Artifact Creation Log ==="
            echo "Timestamp: $(date -u)"

            # Create source tarball
            echo "Creating source tarball..."
            tar czf "${SRC_DIR}"/../apache-cloudberry-incubating-src.tgz -C "${SRC_DIR}"/.. ./cloudberry
            mv "${SRC_DIR}"/../apache-cloudberry-incubating-src.tgz "${SRC_DIR}"

            # Verify tarball contents
            echo "Verifying source tarball contents..."
            if ! tar tzf "${SRC_DIR}"/apache-cloudberry-incubating-src.tgz > /dev/null; then
              echo "::error::Source tarball verification failed"
              exit 1
            fi

            # Create RPM
            echo "Creating RPM package..."
            rpmdev-setuptree
            ln -s "${SRC_DIR}"/../cloudberry-devops-release/packaging/rpm/el/SPECS/apache-cloudberry-db-incubating.spec "${HOME}"/rpmbuild/SPECS/apache-cloudberry-db-incubating.spec
            cp "${SRC_DIR}"/LICENSE /usr/local/cloudberry-db

            "${SRC_DIR}"/../cloudberry-devops-release/scripts/build-rpm.sh --version "${CBDB_VERSION}" --release "${BUILD_NUMBER}"

            # Get OS version and move RPM
            os_version=$(grep -oP '(?<=^VERSION_ID=")[0-9]' /etc/os-release)
            RPM_FILE="${HOME}"/rpmbuild/RPMS/x86_64/apache-cloudberry-db-incubating-"${CBDB_VERSION}"-"${BUILD_NUMBER}".el"${os_version}".x86_64.rpm
            cp "${RPM_FILE}" "${SRC_DIR}"

            # Get package information
            echo "Package Information:"
            rpm -qip "${RPM_FILE}"

            # Verify critical files in RPM
            echo "Verifying critical files in RPM..."
            for binary in "bin/postgres" "bin/psql"; do
              if ! rpm -qlp "${RPM_FILE}" | grep -q "${binary}$"; then
                echo "::error::Critical binary '${binary}' not found in RPM"
                exit 1
              fi
            done

            # Record checksums
            echo "Calculating checksums..."
            sha256sum "${RPM_FILE}" | tee -a build-logs/details/checksums.log
            sha256sum "${SRC_DIR}"/apache-cloudberry-incubating-src.tgz | tee -a build-logs/details/checksums.log

            echo "Artifacts created and verified successfully"

          } 2>&1 | tee -a build-logs/details/artifact-creation.log

      - name: Run Apache Cloudberry unittest script
        if: needs.check-skip.outputs.should_skip != 'true'
        env:
          SRC_DIR: ${{ github.workspace }}
        run: |
          set -eo pipefail
          chmod +x "${SRC_DIR}"/../cloudberry-devops-release/build_automation/cloudberry/scripts/unittest-cloudberry.sh
          if ! time su - gpadmin -c "cd ${SRC_DIR} && SRC_DIR=${SRC_DIR} ${SRC_DIR}/../cloudberry-devops-release/build_automation/cloudberry/scripts/unittest-cloudberry.sh"; then
            echo "::error::Unittest script failed"
            exit 1
          fi

      - name: Generate Build Job Summary End
        if: always()
        run: |
          {
            echo "## Build Results"
            echo "- End Time: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Capture Build Config
        if: needs.check-skip.outputs.should_skip != 'true'
        id: build-config
        shell: bash {0}
        run: |

          PG_CONFIG_CONFIGURE="$(/usr/local/cloudberry-db/bin/pg_config --configure | sed "s/'//g")"
          POSTGRES_VERSION="$(/usr/local/cloudberry-db/bin/postgres --version)"
          CLOUDBERRY_VERSION="$(/usr/local/cloudberry-db/bin/postgres --gp-version)"

          # Write outputs to $GITHUB_OUTPUT
          {
            echo "pg_config_configure=${PG_CONFIG_CONFIGURE}"
            echo "postgres_version=${POSTGRES_VERSION}"
            echo "cloudberry_version=${CLOUDBERRY_VERSION}"
          } >> "$GITHUB_OUTPUT"

      - name: Upload build logs
        if: needs.check-skip.outputs.should_skip != 'true'
        uses: actions/upload-artifact@v4
        with:
          name: build-logs-${{ env.BUILD_TIMESTAMP }}
          path: |
            build-logs/
          retention-days: ${{ env.LOG_RETENTION_DAYS }}

      - name: Upload Cloudberry RPM build artifacts
        if: needs.check-skip.outputs.should_skip != 'true'
        uses: actions/upload-artifact@v4
        with:
          name: apache-cloudberry-db-incubating-rpm-build-artifacts
          retention-days: ${{ env.LOG_RETENTION_DAYS }}
          if-no-files-found: error
          path: |
            *.rpm

      - name: Upload Cloudberry source build artifacts
        if: needs.check-skip.outputs.should_skip != 'true'
        uses: actions/upload-artifact@v4
        with:
          name: apache-cloudberry-db-incubating-source-build-artifacts
          retention-days: ${{ env.LOG_RETENTION_DAYS }}
          if-no-files-found: error
          path: |
            apache-cloudberry-incubating-src.tgz

  ## ======================================================================
  ## Job: record-build-environment
  ## ======================================================================

  record-build-environment:
    name: Record Build Environment
    needs:
      - record-workflow-start
      - check-skip
      - build
    runs-on: ubuntu-latest
    container:
      image: postgres:15
    steps:
      - name: Insert Job Environment into Database
        shell: bash {0}
        env:
          PGHOST: ${{ secrets.DB_HOST }}
          PGPORT: ${{ secrets.DB_PORT }}
          PGDATABASE: cloudberry_metrics
          PGUSER: github_actions
          PGPASSWORD: ${{ secrets.DB_GITHUB_ACTIONS_PASSWORD }}
        run: |
          set -e  # Exit on error

          # Insert job environment record
          JOB_ENV_ID=$(psql sslmode=require -v ON_ERROR_STOP=1 -qtAX <<EOF
          INSERT INTO job_environments (
            workflow_run_id, job_name, os_name, os_version, kernel_version,
            cpu_count, cpu_model, total_memory_mb, shared_memory,
            disk_total, disk_used, disk_available, network_info,
            process_count, container_id, container_image
          ) VALUES (
            (SELECT workflow_run_id FROM workflow_runs WHERE github_run_id = '${{ github.run_id }}'),
            'Build Apache Cloudberry',
            '${{ needs.build.outputs.os_name }}',
            '${{ needs.build.outputs.os_version }}',
            '${{ needs.build.outputs.kernel_version }}',
             ${{ needs.build.outputs.cpu_count }},
            '${{ needs.build.outputs.cpu_model }}',
             ${{ needs.build.outputs.total_memory_mb }},
            '${{ needs.build.outputs.shared_memory }}',
            '${{ needs.build.outputs.disk_total }}',
            '${{ needs.build.outputs.disk_used }}',
            '${{ needs.build.outputs.disk_available }}',
            '${{ needs.build.outputs.network_info }}',
             ${{ needs.build.outputs.process_count }},
            '${{ needs.build.outputs.container_id }}',
            '${{ needs.build.outputs.container_image }}')
          RETURNING job_env_id;
          EOF
          )

          # Verify we got a job environment ID
          if [[ -z "$JOB_ENV_ID" ]]; then
            echo "Error: Failed to insert job environment"
            exit 1
          fi

          # Log the inserted job environment ID
          echo "Inserted Job Environment ID: $JOB_ENV_ID"

  ## ======================================================================
  ## Job: record-build-run
  ## ======================================================================

  record-build-run:
    name: Record Build Run
    needs:
      - record-workflow-start
      - check-skip
      - build
    runs-on: ubuntu-latest
    container:
      image: postgres:15
    steps:
      - name: Insert Build Run into Database
        shell: bash {0}
        env:
          PGHOST: ${{ secrets.DB_HOST }}
          PGPORT: ${{ secrets.DB_PORT }}
          PGDATABASE: cloudberry_metrics
          PGUSER: github_actions
          PGPASSWORD: ${{ secrets.DB_GITHUB_ACTIONS_PASSWORD }}
        run: |
          set -e  # Exit on error

          # Insert job environment record
          BUILD_RUN_ID=$(psql sslmode=require -v ON_ERROR_STOP=1 -qtAX <<EOF
          INSERT INTO build_runs (
            workflow_run_id, pg_config_configure, postgres_version, cloudberry_version
          ) VALUES (
            (SELECT workflow_run_id FROM workflow_runs WHERE github_run_id = '${{ github.run_id }}'),
            '${{ needs.build.outputs.pg_config_configure }}',
            '${{ needs.build.outputs.postgres_version }}',
            '${{ needs.build.outputs.cloudberry_version }}')
          RETURNING build_run_id;
          EOF
          )

          # Verify we got a Build Run ID
          if [[ -z "$BUILD_RUN_ID" ]]; then
            echo "Error: Failed to insert job environment"
            exit 1
          fi

          # Log the inserted Build Run ID
          echo "Inserted Job Environment ID: $BUILD_RUN_ID"

  ## ======================================================================
  ## Job: rpm-install-test
  ## ======================================================================

  rpm-install-test:
    name: RPM Install Test Apache Cloudberry
    needs:
      - record-workflow-start
      - check-skip
      - build
      - record-build-environment
      - record-build-run
    runs-on: ubuntu-latest
    timeout-minutes: 120

    container:
      image: apache/incubator-cloudberry:cbdb-test-rocky9-latest
      options: >-
        --user root
        -h cdw

    steps:
      - name: Skip Check
        if: needs.check-skip.outputs.should_skip == 'true'
        run: |
          echo "RPM install test skipped via CI skip flag" >> "$GITHUB_STEP_SUMMARY"
          exit 0

      - name: Download Cloudberry RPM build artifacts
        if: needs.check-skip.outputs.should_skip != 'true'
        uses: actions/download-artifact@v4
        with:
          name: apache-cloudberry-db-incubating-rpm-build-artifacts
          path: ${{ github.workspace }}/rpm_build_artifacts
          merge-multiple: false

      - name: Cloudberry Environment Initialization
        if: needs.check-skip.outputs.should_skip != 'true'
        env:
          LOGS_DIR: install-logs
        run: |
          set -eo pipefail
          if ! su - gpadmin -c "/tmp/init_system.sh"; then
            echo "::error::Container initialization failed"
            exit 1
          fi

          mkdir -p "${LOGS_DIR}/details"
          chown -R gpadmin:gpadmin .
          chmod -R 755 .
          chmod 777 "${LOGS_DIR}"

          df -h | tee -a "${LOGS_DIR}/details/disk-usage.log"
          free -h | tee -a "${LOGS_DIR}/details/memory-usage.log"

          {
            echo "=== Environment Information ==="
            uname -a
            df -h
            free -h
            env
          } | tee -a "${LOGS_DIR}/details/environment.log"

          echo "SRC_DIR=${GITHUB_WORKSPACE}" | tee -a "$GITHUB_ENV"

      - name: Verify RPM artifacts
        if: needs.check-skip.outputs.should_skip != 'true'
        id: verify-artifacts
        run: |
          set -eo pipefail

          RPM_FILE=$(ls "${GITHUB_WORKSPACE}"/rpm_build_artifacts/apache-cloudberry-db-incubating*.rpm)
          if [ ! -f "${RPM_FILE}" ]; then
            echo "::error::RPM file not found"
            exit 1
          fi

          echo "rpm_file=${RPM_FILE}" >> "$GITHUB_OUTPUT"

          echo "Verifying RPM artifacts..."
          {
            echo "=== RPM Verification Summary ==="
            echo "Timestamp: $(date -u)"
            echo "RPM File: ${RPM_FILE}"

            # Get RPM metadata and verify contents
            echo "Package Information:"
            rpm -qip "${RPM_FILE}"

            # Get key RPM attributes for verification
            RPM_VERSION=$(rpm -qp --queryformat "%{VERSION}" "${RPM_FILE}")
            RPM_RELEASE=$(rpm -qp --queryformat "%{RELEASE}" "${RPM_FILE}")
            echo "version=${RPM_VERSION}" >> "$GITHUB_OUTPUT"
            echo "release=${RPM_RELEASE}" >> "$GITHUB_OUTPUT"

            # Verify expected binaries are in the RPM
            echo "Verifying critical files in RPM..."
            for binary in "bin/postgres" "bin/psql"; do
              if ! rpm -qlp "${RPM_FILE}" | grep -q "${binary}$"; then
                echo "::error::Critical binary '${binary}' not found in RPM"
                exit 1
              fi
            done

            echo "RPM Details:"
            echo "- Version: ${RPM_VERSION}"
            echo "- Release: ${RPM_RELEASE}"

            # Calculate and store checksum
            echo "Checksum:"
            sha256sum "${RPM_FILE}"

          } 2>&1 | tee -a install-logs/details/rpm-verification.log

      - name: Install Cloudberry RPM
        if: success() && needs.check-skip.outputs.should_skip != 'true'
        env:
          RPM_FILE: ${{ steps.verify-artifacts.outputs.rpm_file }}
          RPM_VERSION: ${{ steps.verify-artifacts.outputs.version }}
          RPM_RELEASE: ${{ steps.verify-artifacts.outputs.release }}
        run: |
          set -eo pipefail

          if [ -z "${RPM_FILE}" ]; then
            echo "::error::RPM_FILE environment variable is not set"
            exit 1
          fi

          {
            echo "=== RPM Installation Log ==="
            echo "Timestamp: $(date -u)"
            echo "RPM File: ${RPM_FILE}"
            echo "Version: ${RPM_VERSION}"
            echo "Release: ${RPM_RELEASE}"

            # Clean install location
            rm -rf /usr/local/cloudberry-db

            # Install RPM
            echo "Starting installation..."
            if ! time dnf install -y "${RPM_FILE}"; then
              echo "::error::RPM installation failed"
              exit 1
            fi

            echo "Installation completed successfully"
            rpm -qi apache-cloudberry-db-incubating
            echo "Installed files:"
            rpm -ql apache-cloudberry-db-incubating
          } 2>&1 | tee -a install-logs/details/rpm-installation.log

      - name: Upload install logs
        if: needs.check-skip.outputs.should_skip != 'true'
        uses: actions/upload-artifact@v4
        with:
          name: install-logs-${{ needs.build.outputs.build_timestamp }}
          path: |
            install-logs/
          retention-days: ${{ env.LOG_RETENTION_DAYS }}

      - name: Generate Install Test Job Summary End
        if: always()
        shell: bash {0}
        run: |
          {
            echo "# Installed Package Summary"
            echo "\`\`\`"

            rpm -qi apache-cloudberry-db-incubating
            echo "\`\`\`"
          } >> "$GITHUB_STEP_SUMMARY" || true

  ## ======================================================================
  ## Job: test
  ## ======================================================================

  # WARNING: When adding new pg_settings key/value pairs:
  # 1. Add the new setting with empty string ("") in all matrix entries
  # 2. Update the "Run Tests" step to check and apply the new setting
  # 3. Example: pg_settings.new_setting must be added to ALL matrix entries

  test:
    name: ${{ matrix.test }}
    needs:
      - check-skip
      - record-workflow-start
      - build
      - record-build-environment
      - record-build-run
    runs-on: ubuntu-latest
    timeout-minutes: 120
    # actionlint-allow matrix[*].pg_settings
    strategy:
      fail-fast: false  # Continue with other tests if one fails

      matrix:
        test:
          - ic-good-opt-off
          - ic-good-opt-on
          - ic-cbdb-parallel
          - ic-expandshrink
          - ic-singlenode
          - ic-resgroup-v2
          - ic-contrib
          - ic-gpcontrib
        include:
          - test: ic-good-opt-off
            make_configs:
              - src/test/regress:installcheck-good
            num_primary_mirror_pairs: 3
            pg_settings:
              optimizer: "off"
          - test: ic-good-opt-on
            make_configs:
              - src/test/regress:installcheck-good
            num_primary_mirror_pairs: 3
            pg_settings:
              optimizer: "on"
          - test: ic-cbdb-parallel
            make_configs:
              - src/test/regress:installcheck-cbdb-parallel
            num_primary_mirror_pairs: 3
            pg_settings:
              optimizer: ""
          - test: ic-expandshrink
            make_configs:
              - src/test/isolation2:installcheck-expandshrink
            num_primary_mirror_pairs: 3
            pg_settings:
              optimizer: ""
          - test: ic-singlenode
            make_configs:
              - src/test/isolation:installcheck-singlenode
              - src/test/singlenode_regress:installcheck-singlenode
              - src/test/singlenode_isolation2:installcheck-singlenode
            num_primary_mirror_pairs: 0
            pg_settings:
              optimizer: ""
          - test: ic-resgroup-v2
            make_configs:
              - src/test/isolation2:installcheck-resgroup-v2
            num_primary_mirror_pairs: 3
            pg_settings:
              optimizer: ""
          - test: ic-contrib
            make_configs:
              - contrib/auto_explain:installcheck
              - contrib/citext:installcheck
              - contrib/btree_gin:installcheck
              - contrib/file_fdw:installcheck
              - contrib/formatter_fixedwidth:installcheck
              - contrib/extprotocol:installcheck
              - contrib/dblink:installcheck
              - contrib/pg_trgm:installcheck
              - contrib/indexscan:installcheck
              - contrib/hstore:installcheck
              - contrib/pgcrypto:installcheck
              - contrib/tablefunc:installcheck
              - contrib/passwordcheck:installcheck
              - contrib/sslinfo:installcheck
            num_primary_mirror_pairs: 3
            pg_settings:
              optimizer: ""
          - test: ic-gpcontrib
            make_configs:
              - gpcontrib/orafce:installcheck
              - gpcontrib/pxf_fdw:installcheck
              - gpcontrib/zstd:installcheck
              - gpcontrib/gp_sparse_vector:installcheck
              - gpcontrib/gp_toolkit:installcheck
            num_primary_mirror_pairs: 3
            pg_settings:
              optimizer: ""

    container:
      image: apache/incubator-cloudberry:cbdb-build-rocky9-latest
      options: >-
        --privileged
        --user root
        --hostname cdw
        --shm-size=2gb
        --cgroupns=host
        -v /sys/fs/cgroup:/sys/fs/cgroup:rw

    steps:
      - name: Skip Check
        if: needs.check-skip.outputs.should_skip == 'true'
        run: |
          echo "Test ${{ matrix.test }} skipped via CI skip flag" >> "$GITHUB_STEP_SUMMARY"
          exit 0

      - name: Use timestamp from previous job
        if: needs.check-skip.outputs.should_skip != 'true'
        run: |
          echo "Timestamp from output: ${{ needs.build.outputs.build_timestamp }}"

      - name: Checkout CI Build/Test Scripts (edespino/cloudberry-devops-release)
        if: needs.check-skip.outputs.should_skip != 'true'
        uses: actions/checkout@v4
        with:
          repository: edespino/cloudberry-devops-release
          ref: ic-dev
          path: cloudberry-devops-release

      - name: Move cloudberry-devops-release directory
        if: needs.check-skip.outputs.should_skip != 'true'
        run: |
          set -eo pipefail
          if ! mv "${GITHUB_WORKSPACE}"/cloudberry-devops-release "${GITHUB_WORKSPACE}"/..; then
            echo "::error::Container initialization failed"
            exit 1
          fi

      - name: Cloudberry Environment Initialization
        env:
          LOGS_DIR: build-logs
        run: |
          set -eo pipefail
          if ! su - gpadmin -c "/tmp/init_system.sh"; then
            echo "::error::Container initialization failed"
            exit 1
          fi

          mkdir -p "${LOGS_DIR}/details"
          chown -R gpadmin:gpadmin .
          chmod -R 755 .
          chmod 777 "${LOGS_DIR}"

          df -h | tee -a "${LOGS_DIR}/details/disk-usage.log"
          free -h | tee -a "${LOGS_DIR}/details/memory-usage.log"

          {
            echo "=== Environment Information ==="
            uname -a
            df -h
            free -h
            env
          } | tee -a "${LOGS_DIR}/details/environment.log"

          echo "SRC_DIR=${GITHUB_WORKSPACE}" | tee -a "$GITHUB_ENV"

      - name: Setup cgroups
        if: needs.check-skip.outputs.should_skip != 'true'
        shell: bash
        run: |
          set -uxo pipefail

          echo "Current mounts:"
          mount | grep cgroup

          CGROUP_BASEDIR=/sys/fs/cgroup

          # 1. Basic setup with permissions
          sudo chmod -R 777 ${CGROUP_BASEDIR}/
          sudo mkdir -p ${CGROUP_BASEDIR}/gpdb
          sudo chmod -R 777 ${CGROUP_BASEDIR}/gpdb
          sudo chown -R gpadmin:gpadmin ${CGROUP_BASEDIR}/gpdb

          # 2. Enable controllers
          sudo bash -c "echo '+cpu +cpuset +memory +io' > ${CGROUP_BASEDIR}/cgroup.subtree_control" || true
          sudo bash -c "echo '+cpu +cpuset +memory +io' > ${CGROUP_BASEDIR}/gpdb/cgroup.subtree_control" || true

          # 3. CPU settings
          sudo bash -c "echo 'max 100000' > ${CGROUP_BASEDIR}/gpdb/cpu.max" || true
          sudo bash -c "echo '100' > ${CGROUP_BASEDIR}/gpdb/cpu.weight" || true
          sudo bash -c "echo '0' > ${CGROUP_BASEDIR}/gpdb/cpu.weight.nice" || true
          sudo bash -c "echo 0-$(( $(nproc) - 1 )) > ${CGROUP_BASEDIR}/gpdb/cpuset.cpus" || true
          sudo bash -c "echo '0' > ${CGROUP_BASEDIR}/gpdb/cpuset.mems" || true

          # 4. Memory settings
          sudo bash -c "echo 'max' > ${CGROUP_BASEDIR}/gpdb/memory.max" || true
          sudo bash -c "echo '0' > ${CGROUP_BASEDIR}/gpdb/memory.min" || true
          sudo bash -c "echo 'max' > ${CGROUP_BASEDIR}/gpdb/memory.high" || true

          # 5. IO settings
          echo "Available block devices:"
          lsblk

          sudo bash -c "
            if [ -f \${CGROUP_BASEDIR}/gpdb/io.stat ]; then
              echo 'Detected IO devices:'
              cat \${CGROUP_BASEDIR}/gpdb/io.stat
            fi
            echo '' > \${CGROUP_BASEDIR}/gpdb/io.max || true
          "

          # 6. Fix permissions again after all writes
          sudo chmod -R 777 ${CGROUP_BASEDIR}/gpdb
          sudo chown -R gpadmin:gpadmin ${CGROUP_BASEDIR}/gpdb

          # 7. Check required files
          echo "Checking required files:"
          required_files=(
              "cgroup.procs"
              "cpu.max"
              "cpu.pressure"
              "cpu.weight"
              "cpu.weight.nice"
              "cpu.stat"
              "cpuset.cpus"
              "cpuset.mems"
              "cpuset.cpus.effective"
              "cpuset.mems.effective"
              "memory.current"
              "io.max"
          )

          for file in "${required_files[@]}"; do
              if [ -f "${CGROUP_BASEDIR}/gpdb/$file" ]; then
                  echo "✓ $file exists"
                  ls -l "${CGROUP_BASEDIR}/gpdb/$file"
              else
                  echo "✗ $file missing"
              fi
          done

          # 8. Test subdirectory creation
          echo "Testing subdirectory creation..."
          sudo -u gpadmin bash -c "
            TEST_DIR=\${CGROUP_BASEDIR}/gpdb/test6448
            if mkdir -p \$TEST_DIR; then
              echo 'Created test directory'
              sudo chmod -R 777 \$TEST_DIR
              if echo \$\$ > \$TEST_DIR/cgroup.procs; then
                echo 'Successfully wrote to cgroup.procs'
                cat \$TEST_DIR/cgroup.procs
                # Move processes back to parent before cleanup
                echo \$\$ > \${CGROUP_BASEDIR}/gpdb/cgroup.procs
              else
                echo 'Failed to write to cgroup.procs'
                ls -la \$TEST_DIR/cgroup.procs
              fi
              ls -la \$TEST_DIR/
              rmdir \$TEST_DIR || {
                echo 'Moving all processes to parent before cleanup'
                cat \$TEST_DIR/cgroup.procs | while read pid; do
                  echo \$pid > \${CGROUP_BASEDIR}/gpdb/cgroup.procs 2>/dev/null || true
                done
                rmdir \$TEST_DIR
              }
            else
              echo 'Failed to create test directory'
            fi
          "

          # 9. Verify setup as gpadmin user
          echo "Testing cgroup access as gpadmin..."
          sudo -u gpadmin bash -c "
            echo 'Checking mounts...'
            mount | grep cgroup

            echo 'Checking /proc/self/mounts...'
            cat /proc/self/mounts | grep cgroup

            if ! grep -q cgroup2 /proc/self/mounts; then
                echo 'ERROR: cgroup2 mount NOT visible to gpadmin'
                exit 1
            fi
            echo 'SUCCESS: cgroup2 mount visible to gpadmin'

            if ! [ -w ${CGROUP_BASEDIR}/gpdb ]; then
                echo 'ERROR: gpadmin cannot write to gpdb cgroup'
                exit 1
            fi
            echo 'SUCCESS: gpadmin can write to gpdb cgroup'

            echo 'Verifying key files content:'
            echo 'cpu.max:'
            cat ${CGROUP_BASEDIR}/gpdb/cpu.max || echo 'Failed to read cpu.max'
            echo 'cpuset.cpus:'
            cat ${CGROUP_BASEDIR}/gpdb/cpuset.cpus || echo 'Failed to read cpuset.cpus'
            echo 'cgroup.subtree_control:'
            cat ${CGROUP_BASEDIR}/gpdb/cgroup.subtree_control || echo 'Failed to read cgroup.subtree_control'
          "

          # 10. Show final state
          echo "Final cgroup state:"
          ls -la ${CGROUP_BASEDIR}/gpdb/

          echo "Cgroup setup completed successfully"

      - name: "Generate Test Job Summary Start: ${{ matrix.test }}"
        if: always()
        run: |
          {
            echo "# Test Job Summary: ${{ matrix.test }}"
            echo "## Environment"
            echo "- Start Time: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"

            if [[ "${{ needs.check-skip.outputs.should_skip }}" == "true" ]]; then
              echo "## Skip Status"
              echo "✓ Test execution skipped via CI skip flag"
            else
              echo "- OS Version: $(cat /etc/redhat-release)"
            fi
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Download Cloudberry RPM build artifacts
        if: needs.check-skip.outputs.should_skip != 'true'
        uses: actions/download-artifact@v4
        with:
          name: apache-cloudberry-db-incubating-rpm-build-artifacts
          path: ${{ github.workspace }}/rpm_build_artifacts
          merge-multiple: false

      - name: Download Cloudberry Source build artifacts
        if: needs.check-skip.outputs.should_skip != 'true'
        uses: actions/download-artifact@v4
        with:
          name: apache-cloudberry-db-incubating-source-build-artifacts
          path: ${{ github.workspace }}/source_build_artifacts
          merge-multiple: false

      - name: Verify downloaded artifacts
        if: needs.check-skip.outputs.should_skip != 'true'
        id: verify-artifacts
        run: |
          set -eo pipefail

          SRC_TARBALL_FILE=$(ls "${GITHUB_WORKSPACE}"/source_build_artifacts/apache-cloudberry-incubating-src.tgz)
          if [ ! -f "${SRC_TARBALL_FILE}" ]; then
            echo "::error::SRC TARBALL file not found"
            exit 1
          fi

          echo "src_tarball_file=${SRC_TARBALL_FILE}" >> "$GITHUB_OUTPUT"

          echo "Verifying SRC TARBALL artifacts..."
          {
            echo "=== SRC TARBALL Verification Summary ==="
            echo "Timestamp: $(date -u)"
            echo "SRC TARBALL File: ${SRC_TARBALL_FILE}"

            # Calculate and store checksum
            echo "Checksum:"
            sha256sum "${SRC_TARBALL_FILE}"

          } 2>&1 | tee -a build-logs/details/src-tarball-verification.log

          RPM_FILE=$(ls "${GITHUB_WORKSPACE}"/rpm_build_artifacts/apache-cloudberry-db-incubating*.rpm)
          if [ ! -f "${RPM_FILE}" ]; then
            echo "::error::RPM file not found"
            exit 1
          fi

          echo "rpm_file=${RPM_FILE}" >> "$GITHUB_OUTPUT"

          echo "Verifying RPM artifacts..."
          {
            echo "=== RPM Verification Summary ==="
            echo "Timestamp: $(date -u)"
            echo "RPM File: ${RPM_FILE}"

            # Get RPM metadata and verify contents
            echo "Package Information:"
            rpm -qip "${RPM_FILE}"

            # Get key RPM attributes for verification
            RPM_VERSION=$(rpm -qp --queryformat "%{VERSION}" "${RPM_FILE}")
            RPM_RELEASE=$(rpm -qp --queryformat "%{RELEASE}" "${RPM_FILE}")
            echo "version=${RPM_VERSION}" >> "$GITHUB_OUTPUT"
            echo "release=${RPM_RELEASE}" >> "$GITHUB_OUTPUT"

            # Verify expected binaries are in the RPM
            echo "Verifying critical files in RPM..."
            for binary in "bin/postgres" "bin/psql"; do
              if ! rpm -qlp "${RPM_FILE}" | grep -q "${binary}$"; then
                echo "::error::Critical binary '${binary}' not found in RPM"
                exit 1
              fi
            done

            echo "RPM Details:"
            echo "- Version: ${RPM_VERSION}"
            echo "- Release: ${RPM_RELEASE}"

            # Calculate and store checksum
            echo "Checksum:"
            sha256sum "${RPM_FILE}"

          } 2>&1 | tee -a build-logs/details/rpm-verification.log

      - name: Install Cloudberry RPM
        if: success() && needs.check-skip.outputs.should_skip != 'true'
        env:
          RPM_FILE: ${{ steps.verify-artifacts.outputs.rpm_file }}
          RPM_VERSION: ${{ steps.verify-artifacts.outputs.version }}
          RPM_RELEASE: ${{ steps.verify-artifacts.outputs.release }}
        run: |
          set -eo pipefail

          if [ -z "${RPM_FILE}" ]; then
            echo "::error::RPM_FILE environment variable is not set"
            exit 1
          fi

          {
            echo "=== RPM Installation Log ==="
            echo "Timestamp: $(date -u)"
            echo "RPM File: ${RPM_FILE}"
            echo "Version: ${RPM_VERSION}"
            echo "Release: ${RPM_RELEASE}"

            # Clean install location
            rm -rf /usr/local/cloudberry-db

            # Install RPM
            echo "Starting installation..."
            if ! time dnf install -y "${RPM_FILE}"; then
              echo "::error::RPM installation failed"
              exit 1
            fi

            echo "Installation completed successfully"
            rpm -qi apache-cloudberry-db-incubating
          } 2>&1 | tee -a build-logs/details/rpm-installation.log

      - name: Extract source tarball
        if: success() && needs.check-skip.outputs.should_skip != 'true'
        env:
          SRC_TARBALL_FILE: ${{ steps.verify-artifacts.outputs.src_tarball_file }}
          SRC_DIR: ${{ github.workspace }}
        run: |
          set -eo pipefail

          {
            echo "=== Source Extraction Log ==="
            echo "Timestamp: $(date -u)"

            echo "Starting extraction..."
            if ! time tar zxf "${SRC_TARBALL_FILE}" -C "${SRC_DIR}"/.. ; then
              echo "::error::Source extraction failed"
              exit 1
            fi

            echo "Extraction completed successfully"
            echo "Extracted contents:"
            ls -la "${SRC_DIR}/../cloudberry"
            echo "Directory size:"
            du -sh "${SRC_DIR}/../cloudberry"
          } 2>&1 | tee -a build-logs/details/source-extraction.log

      - name: Create Apache Cloudberry demo cluster
        if: success() && needs.check-skip.outputs.should_skip != 'true'
        env:
          SRC_DIR: ${{ github.workspace }}
        run: |
          set -eo pipefail

          {
            chmod +x "${SRC_DIR}"/../cloudberry-devops-release/build_automation/cloudberry/scripts/create-cloudberry-demo-cluster.sh
            if ! time su - gpadmin -c "cd ${SRC_DIR} && NUM_PRIMARY_MIRROR_PAIRS='${{ matrix.num_primary_mirror_pairs }}' SRC_DIR=${SRC_DIR} ${SRC_DIR}/../cloudberry-devops-release/build_automation/cloudberry/scripts/create-cloudberry-demo-cluster.sh"; then
              echo "::error::Demo cluster creation failed"
              exit 1
            fi

          } 2>&1 | tee -a build-logs/details/create-cloudberry-demo-cluster.log

      - name: "Run Tests: ${{ matrix.test }}"
        if: success() && needs.check-skip.outputs.should_skip != 'true'
        env:
          SRC_DIR: ${{ github.workspace }}
        shell: bash {0}
        run: |
          set -o pipefail

          # Initialize test status
          overall_status=0

          # Create logs directory structure
          mkdir -p build-logs/details

          # WARNING: PostgreSQL Settings
          # When adding new pg_settings key/value pairs:
          # 1. Add a new check below for the setting
          # 2. Follow the same pattern as optimizer
          # 3. Update matrix entries to include the new setting

          # Set PostgreSQL options if defined
          PG_OPTS=""
          if [[ "${{ matrix.pg_settings.optimizer != '' }}" == "true" ]]; then
            PG_OPTS="$PG_OPTS -c optimizer=${{ matrix.pg_settings.optimizer }}"
          fi

          # Read configs into array
          IFS=' ' read -r -a configs <<< "${{ join(matrix.make_configs, ' ') }}"

          echo "=== Starting test execution for ${{ matrix.test }} ==="
          echo "Number of configurations to execute: ${#configs[@]}"
          echo ""

          # Execute each config separately
          for ((i=0; i<${#configs[@]}; i++)); do
            config="${configs[$i]}"
            IFS=':' read -r dir target <<< "$config"

            echo "=== Executing configuration $((i+1))/${#configs[@]} ==="
            echo "Make command: make -C $dir $target"
            echo "Environment:"
            echo "- PGOPTIONS: ${PG_OPTS}"

            # Create unique log file for this configuration
            config_log="build-logs/details/make-${{ matrix.test }}-config$i.log"

            # Execute test script with proper environment setup
            if ! time su - gpadmin -c "cd ${SRC_DIR} && \
                 MAKE_NAME='${{ matrix.test }}-config$i' \
                 MAKE_TARGET='$target' \
                 MAKE_DIRECTORY='-C $dir' \
                 PGOPTIONS='${PG_OPTS}' \
                 SRC_DIR='${SRC_DIR}' \
                 ${SRC_DIR}/../cloudberry-devops-release/build_automation/cloudberry/scripts/test-cloudberry.sh" \
                 2>&1 | tee "$config_log"; then
              echo "::warning::Test execution failed for configuration $((i+1)): make -C $dir $target"
              overall_status=1
            fi

            echo "Log file: $config_log"
            echo "=== End configuration $((i+1)) execution ==="
            echo ""
          done

          echo "=== Test execution completed ==="
          echo "Log files:"
          ls -l build-logs/details/

          # Store number of configurations for parsing step
          echo "NUM_CONFIGS=${#configs[@]}" >> "$GITHUB_ENV"

          # Report overall status
          if [ $overall_status -eq 0 ]; then
            echo "All test executions completed successfully"
          else
            echo "::warning::Some test executions failed, check individual logs for details"
          fi

          exit $overall_status

      - name: "Parse Test Results: ${{ matrix.test }}"
        id: test-results
        if: always() && needs.check-skip.outputs.should_skip != 'true'
        env:
          SRC_DIR: ${{ github.workspace }}
        shell: bash {0}
        run: |
          set -o pipefail

          overall_status=0

          # Get configs array to create context for results
          IFS=' ' read -r -a configs <<< "${{ join(matrix.make_configs, ' ') }}"

          echo "=== Starting results parsing for ${{ matrix.test }} ==="
          echo "Number of configurations to parse: ${#configs[@]}"
          echo ""

          # Parse each configuration's results independently
          for ((i=0; i<NUM_CONFIGS; i++)); do
            config="${configs[$i]}"
            IFS=':' read -r dir target <<< "$config"

            config_log="build-logs/details/make-${{ matrix.test }}-config$i.log"

            echo "=== Parsing results for configuration $((i+1))/${NUM_CONFIGS} ==="
            echo "Make command: make -C $dir $target"
            echo "Log file: $config_log"

            if [ ! -f "$config_log" ]; then
              echo "::error::Log file not found: $config_log"
              {
                echo "MAKE_COMMAND=make -C $dir $target"
                echo "STATUS=missing_log"
                echo "TOTAL_TESTS=0"
                echo "FAILED_TESTS=0"
                echo "PASSED_TESTS=0"
                echo "IGNORED_TESTS=0"
              } > "test_results.$i.txt"
              overall_status=1
              continue
            fi

            # Parse this configuration's results

            MAKE_NAME="${{ matrix.test }}-config$i" \
            "${SRC_DIR}"/../cloudberry-devops-release/build_automation/cloudberry/scripts/parse-test-results.sh "$config_log"
            status_code=$?

            {
                echo "SUITE_NAME=${{ matrix.test }}"
                echo "DIR=${dir}"
                echo "TARGET=${target}"
            } >> test_results.txt

            # Process return code
            case $status_code in
              0)  # All tests passed
                  echo "All tests passed successfully"
                  if [ -f test_results.txt ]; then
                    (echo "MAKE_COMMAND=\"make -C $dir $target\""; cat test_results.txt) > "test_results.${{ matrix.test }}.$i.txt"
                    rm test_results.txt
                  fi
                  ;;
              1)  # Tests failed but parsed successfully
                  echo "Test failures detected but properly parsed"
                  if [ -f test_results.txt ]; then
                    (echo "MAKE_COMMAND=\"make -C $dir $target\""; cat test_results.txt) > "test_results.${{ matrix.test }}.$i.txt"
                    rm test_results.txt
                  fi
                  overall_status=1
                  ;;
              2)  # Parse error or missing file
                  echo "::warning::Could not parse test results properly for configuration $((i+1))"
                  {
                    echo "MAKE_COMMAND=\"make -C $dir $target\""
                    echo "STATUS=parse_error"
                    echo "TOTAL_TESTS=0"
                    echo "FAILED_TESTS=0"
                    echo "PASSED_TESTS=0"
                    echo "IGNORED_TESTS=0"
                  } | tee "test_results.${{ matrix.test }}.$i.txt"
                  overall_status=1
                  rm -f test_results.txt
                  ;;
              *)  # Unexpected error
                  echo "::warning::Unexpected error during test results parsing for configuration $((i+1))"
                  {
                    echo "MAKE_COMMAND=\"make -C $dir $target\""
                    echo "STATUS=unknown_error"
                    echo "TOTAL_TESTS=0"
                    echo "FAILED_TESTS=0"
                    echo "PASSED_TESTS=0"
                    echo "IGNORED_TESTS=0"
                  } | tee "test_results.${{ matrix.test }}.$i.txt"
                  overall_status=1
                  rm -f test_results.txt
                  ;;
            esac

            echo "Results stored in test_results.$i.txt"
            echo "=== End parsing for configuration $((i+1)) ==="
            echo ""
          done

          # Report status of results files
          echo "=== Results file status ==="
          echo "Generated results files:"
          for ((i=0; i<NUM_CONFIGS; i++)); do
            if [ -f "test_results.${{ matrix.test }}.$i.txt" ]; then
              echo "- test_results.${{ matrix.test }}.$i.txt exists"
              echo ""
            else
              echo "::error::Missing results file: test_results.${{ matrix.test }}.$i.txt"
              overall_status=1
            fi
          done

          exit $overall_status

      - name: Check and Display Regression Diffs
        if: always()
        run: |
          # Search for regression.diffs recursively
          found_file=$(find . -type f -name "regression.diffs" | head -n 1)
          if [[ -n "$found_file" ]]; then
            echo "Found regression.diffs at: $found_file"
            cat "$found_file"
          else
            echo "No regression.diffs file found in the hierarchy."
          fi

      - name: "Generate Test Job Summary End: ${{ matrix.test }}"
        if: always()
        shell: bash {0}
        run: |
          {
            if [[ "${{ needs.check-skip.outputs.should_skip }}" == "true" ]]; then
              echo "## Test Results - SKIPPED"
              echo "- End Time: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
              exit 0
            fi

            echo "## Test Results"
            echo "- End Time: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"

            # Check if job was cancelled
            if [[ "${{ job.status }}" == "cancelled" ]]; then
              echo "### Test Status"
              echo "🚫 Test execution was cancelled"
              echo ""
              echo "### Execution Summary"
              echo "Test run was interrupted and did not complete. No test results are available."
              exit 0
            fi

            # Process results for each configuration
            IFS=' ' read -r -a configs <<< "${{ join(matrix.make_configs, ' ') }}"

            for ((i=0; i<NUM_CONFIGS; i++)); do
              config="${configs[$i]}"
              IFS=':' read -r dir target <<< "$config"

              echo "### Configuration $((i+1)): \`make -C $dir $target\`"

              if [[ ! -f "test_results.${{ matrix.test }}.$i.txt" ]]; then
                echo "⚠️ No results file found for this configuration"
                continue
              fi

              # Source configuration results
              # shellcheck source=/dev/null
              . "test_results.${{ matrix.test }}.$i.txt"

              # Rest of the code remains the same...
              # Display status with emoji
              echo "#### Status"
              case "${STATUS:-unknown}" in
                passed)
                  echo "✅ All tests passed"
                  ;;
                failed)
                  echo "❌ Some tests failed"
                  ;;
                parse_error)
                  echo "⚠️ Could not parse test results"
                  ;;
                unknown_error)
                  echo "⚠️ Unexpected error during test execution/parsing"
                  ;;
                missing_log)
                  echo "⚠️ Test log file missing"
                  ;;
                *)
                  echo "⚠️ Unknown status: ${status:-unknown}"
                  ;;
              esac

              echo ""
              echo "#### Test Counts"
              echo "| Metric | Count |"
              echo "|--------|-------|"
              echo "| Total Tests | ${TOTAL_TESTS:-0} |"
              echo "| Passed Tests | ${PASSED_TESTS:-0} |"
              echo "| Failed Tests | ${FAILED_TESTS:-0} |"
              echo "| Ignored Tests | ${IGNORED_TESTS:-0} |"

              # Add failed tests if any
              if [[ -n "${FAILED_TEST_NAMES:-}" && "${FAILED_TESTS:-0}" != "0" ]]; then
                echo ""
                echo "#### Failed Tests"
                echo "${FAILED_TEST_NAMES}" | tr ',' '\n' | while read -r test; do
                  if [[ -n "$test" ]]; then
                    echo "* \`${test}\`"
                  fi
                done
              fi

              # Add ignored tests if any
              if [[ -n "${IGNORED_TEST_NAMES:-}" && "${IGNORED_TESTS:-0}" != "0" ]]; then
                echo ""
                echo "#### Ignored Tests"
                echo "${IGNORED_TEST_NAMES}" | tr ',' '\n' | while read -r test; do
                  if [[ -n "$test" ]]; then
                    echo "* \`${test}\`"
                  fi
                done
              fi

              echo ""
              echo "---"
            done

          } >> "$GITHUB_STEP_SUMMARY" || true

      - name: Upload test logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-logs-${{ matrix.test }}-${{ needs.build.outputs.build_timestamp }}
          path: |
            build-logs/
          retention-days: ${{ env.LOG_RETENTION_DAYS }}

      - name: Upload Test Metadata
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-metadata-${{ matrix.test }}
          path: |
            test_results*.txt
          retention-days: ${{ env.LOG_RETENTION_DAYS }}

      - name: Upload test regression logs
        if: failure() || cancelled()
        uses: actions/upload-artifact@v4
        with:
          name: regression-logs-${{ matrix.test }}-${{ needs.build.outputs.build_timestamp }}
          path: |
            **/regression.out
            **/regression.diffs
            **/results/
            gpAux/gpdemo/datadirs/standby/log/
            gpAux/gpdemo/datadirs/qddir/demoDataDir-1/log/
            gpAux/gpdemo/datadirs/dbfast1/demoDataDir0/log/
            gpAux/gpdemo/datadirs/dbfast2/demoDataDir1/log/
            gpAux/gpdemo/datadirs/dbfast3/demoDataDir2/log/
            gpAux/gpdemo/datadirs/dbfast_mirror1/demoDataDir0/log/
            gpAux/gpdemo/datadirs/dbfast_mirror2/demoDataDir1/log/
            gpAux/gpdemo/datadirs/dbfast_mirror3/demoDataDir2/log/
          retention-days: ${{ env.LOG_RETENTION_DAYS }}

  ## ======================================================================
  ## Job: report
  ## ======================================================================

  report:
    name: Generate Apache Cloudberry Build Report
    needs:
      - check-skip
      - record-workflow-start
      - build
      - record-build-environment
      - record-build-run
      - test
      - rpm-install-test
    if: always()
    runs-on: ubuntu-latest
    steps:
      - name: Generate Final Report
        run: |
          {
            echo "# Apache Cloudberry Build Pipeline Report"

            if [[ "${{ needs.check-skip.outputs.should_skip }}" == "true" ]]; then
              echo "## CI Skip Status"
              echo "✅ CI checks skipped via skip flag"
              echo "- Completion Time: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
            else
              echo "## Job Status"
              echo "- Build Job: ${{ needs.build.result }}"
              echo "- Test Job: ${{ needs.test.result }}"
              echo "- Completion Time: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"

              if [[ "${{ needs.build.result }}" == "success" && "${{ needs.test.result }}" == "success" ]]; then
                echo "✅ Pipeline completed successfully"
              else
                echo "⚠️ Pipeline completed with failures"

                if [[ "${{ needs.build.result }}" != "success" ]]; then
                  echo "### Build Job Failure"
                  echo "Check build logs for details"
                fi

                if [[ "${{ needs.test.result }}" != "success" ]]; then
                  echo "### Test Job Failure"
                  echo "Check test logs and regression files for details"
                fi
              fi
            fi
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Notify on failure
        if: |
          needs.check-skip.outputs.should_skip != 'true' &&
          (needs.build.result != 'success' || needs.test.result != 'success')
        run: |
          echo "::error::Build/Test pipeline failed! Check job summaries and logs for details"
          echo "Timestamp: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
          echo "Build Result: ${{ needs.build.result }}"
          echo "Test Result: ${{ needs.test.result }}"

  ## ======================================================================
  ## Job: record-test-run
  ## ======================================================================

  record-test-run:
    name: Record Test Run
    needs:
      - record-workflow-start
      - check-skip
      - build
      - record-build-environment
      - record-build-run
      - test
      - rpm-install-test
    if: always()
    runs-on: ubuntu-latest
    container:
      image: postgres:15

    steps:
      - name: Download Test Metadata
        uses: actions/download-artifact@v4
        with:
          path: ${{ github.workspace }}
          pattern: test-metadata*
          merge-multiple: true

      - name: Insert Build Run into Database
        shell: bash {0}
        env:
          PGHOST: ${{ secrets.DB_HOST }}
          PGPORT: ${{ secrets.DB_PORT }}
          PGDATABASE: cloudberry_metrics
          PGUSER: github_actions
          PGPASSWORD: ${{ secrets.DB_GITHUB_ACTIONS_PASSWORD }}
        run: |
          # Track overall success
          insert_success=true

          # Store test run IDs
          declare -a test_run_ids=()

          for test_metadata_file in ./test_results*.txt; do
            echo "Processing $test_metadata_file"

            # Source the test metadata
            # shellcheck source=/dev/null
            . "${test_metadata_file}"

            # Attempt insert
            if ! TEST_RUN_ID=$(psql sslmode=require -v ON_ERROR_STOP=1 -qtAX <<EOF
            INSERT INTO test_runs (
              workflow_run_id,
              suite_name,
              make_directory,
              make_target,
              test_status,
              total_tests,
              passed_tests,
              failed_tests,
              ignored_tests,
              failed_test_names,
              ignored_test_names,
              created_at
            ) VALUES (
              (SELECT workflow_run_id FROM workflow_runs WHERE github_run_id = '${{ github.run_id }}'),
              '${SUITE_NAME}',
              '${DIR}',
              '${TARGET}',
              '${STATUS}',
              ${TOTAL_TESTS:-0},
              ${PASSED_TESTS:-0},
              ${FAILED_TESTS:-0},
              ${IGNORED_TESTS:-0},
              '${FAILED_TEST_NAMES:-}',
              '${IGNORED_TEST_NAMES:-}',
              NOW())
            RETURNING test_run_id;
          EOF
            ); then
              echo "Error: Failed to insert test run for $test_metadata_file"
              insert_success=false
              continue
            fi

            # Verify we got an ID
            if [[ -z "$TEST_RUN_ID" ]]; then
              echo "Error: No test run ID returned for $test_metadata_file"
              insert_success=false
              continue
            fi

            # Store successful insert
            test_run_ids+=("$TEST_RUN_ID")
            echo "Successfully inserted Test Run ID: $TEST_RUN_ID for $test_metadata_file"
          done

          # Report results
          echo "Processed ${#test_run_ids[@]} test runs successfully"
          if [[ "$insert_success" != "true" ]]; then
            echo "Error: Some test run inserts failed"
            exit 1
          fi

  ## ======================================================================
  ## Job: record-workflow-end
  ## ======================================================================

  record-workflow-end:
    needs:
      - record-workflow-start
      - check-skip
      - build
      - record-build-environment
      - record-build-run
      - rpm-install-test
      - test
      - record-test-run
    if: always()  # Run even if previous jobs fail
    runs-on: ubuntu-latest
    container:
      image: postgres:15
    steps:
      - name: Record workflow completion
        env:
          PGHOST: ${{ secrets.DB_HOST }}
          PGPORT: ${{ secrets.DB_PORT }}
          PGDATABASE: cloudberry_metrics
          PGUSER: github_actions
          PGPASSWORD: ${{ secrets.DB_GITHUB_ACTIONS_PASSWORD }}
          WORKFLOW_ID: ${{ needs.record-workflow-start.outputs.workflow_id }}
        shell: bash {0}
        run: |
          set -e  # Exit on error

          # Update workflow record with completion time and status
          psql sslmode=require -v ON_ERROR_STOP=1 -qtAX <<EOF
          UPDATE workflow_runs
          SET
            completed_at = NOW(),
            workflow_status = 'completed'
          WHERE workflow_run_id = $WORKFLOW_ID;
          EOF
